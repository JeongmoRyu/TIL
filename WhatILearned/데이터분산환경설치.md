# 데이터분산환경설치

## VMware, Ubuntu, Hadoop 개발환경구축

## VMware 설치

https://www.vmware.com/products/workstation-player.html

## Ubuntu 설치

http://www.ubuntu.com/download/ubuntu/download

```bash
$ wget http://kdd.snu.ac.kr/~kddlab/Project.tar.gz
$ tar zxf Project.tar.gz
$ sudo chown -R hadoop:hadoop Project
$ cd Project
$ sudo mv hadoop-3.2.2 /usr/local/hadoop
$ sudo apt update
$ sudo apt install ssh openjdk-8-jdk ant -y
$ ./set_hadoop_env.sh
$ source ~/.bashrc

$ ssh-keygen -t rsa -P ""
$ cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys

```

## hadoop을 실행하기 위한 준비

```bash
$ source .bashrc
$ hadoop namenode -format
$ start-dfs.sh
$ jps

- 파일 디렉토리 없음을 확인하고 생성
$ hdfs dfs -ls /
$ hdfs dfs -mkdir /user
$ hdfs dfs -mkdir /user/hadoop
```

- 맵 리듀스 코드 컴파일

```bash
$ ant
```

- 예제 실행

```bash
$ cd /home/hadoop/Project
$ hdfs dfs -mkdir wordcount_test
$ hdfs dfs -put data/wordcount-data.txt wordcount_test

맵 리듀스 프로그램이 결과를 저장할 디렉토리를 삭제한 후 프로그램 실행해야함
$ hdfs dfs -rm -r wordcount_test_out
```

- wordcount Mapreduce 알고리즘 코드 실행

```bash
$ cd /home/hadoop/Project
$ hadoop jar ssafy.jar wordcount wordcount_test wordcount_test_out
$ hadoop jar [jar file] [program name] < input arguments...>
```

- 결과 확인

```bash
$ hdfs dfs -cat wordcount_test_out/part-r-00000 | more

$ hdfs dfs -cat wordcount_test_out/part-r-00001 | more
```

```bash
All	1
Almighty	1
Americans	2
Americans:	1
Americas.	1
And	4
But	5
Divided	1
East	1
Finally,	2
For	3
I	3
If	1
In	2
Let	8
Nor	1
North	1
South,	1
The	3
To	5
United	2
West,	1
a	28
--More--
```
